# Fear Not!

*If you're new to RStudio, you've come to the right place. Beyond my advanced projects, I've created this beginner-friendly page to share some basic computations. Whether you're an employer or a colleague visiting, I'm delighted to have your interest.*

*We all have our first "sense of horror" moment when we first encounter RStudio. For me, it was during my first year in a biostatistics class with my teacher, Tessa. She had us working on projects using RStudio during class, and those initial weeks were chaotic. We were all frustrated and terrified by what appeared on our screens---scary red errors seemed to pop up every second, and we felt like we were making no progress at all. However, Tessa remained by our side. She dedicated the beginning of every class to addressing the typical errors we encountered, guiding us toward smart tactics and helpful online resources.*

*By the end of the semester, our perception of RStudio had completely changed. Tessa helped us realize that it wasn't some dark abyss from which no student returns; it was a powerful tool that made statistics easier to compute. We bid farewell to the daunting equations we were accustomed to and began computing statistical techniques at a rapid pace. To this day, every one of my classmates continues to use RStudio with excitement. This software is truly your best friend if you use it wisely.*

## Learning R

1.  *Asking for Help*

2.  *Packages*

3.  *Reading Data*

4.  *Tidying Data*

5.  *Functions*

6.  *Data Visualization*

![](images/IMG_5316-02.png)

### 1. Asking for Help

*Most experts mention asking for help at the end of their tutorials, but I believe it deserves to be first. Learning R involves seeking a lot of assistance, and there are countless online resources available to answer your questions. Below are some of my favorite resources:*

-   ***The Help Center in RStudio**: Located in the bottom right pane of your window, the Help Center provides detailed explanations of each command in R. You can learn about the purpose of each function, as well as their sub-commands and properties. You can also type any command with the `?` symbol in front of it and it will direct you to the same window (e.g., `?plot()`).*

-   ***The R Project Website**: Provides comprehensive documentation and manuals.*

-   ***RStudio Community**: An active forum where you can ask questions.*

-   ***R-Bloggers**:* *A resource for tutorials, tips, and tricks from the R community.*

-   ***YouTube**: Useful tutorials for visual learners.*

-   ***Reddit**: A community where everyone deals with problems using R. Visit Reddit to view a wide range of questions and answers from people around the globe.*

-   ***Generative AI**: An easy tool that can pick out the flaw in your code and guide you toward a solution. However, I recommend you use with caution, as AI can occasionally produce unreliable solutions to your code.*

*By leveraging these resources, you can make your learning journey with R more efficient and less daunting.*

### 2. Packages

*R packages are collections of functions, data, and documentation that extend the capabilities of base R, making it easier and more efficient to perform a wide range of tasks.*

-   *Simplify Complex Tasks*

-   *Improve Data Analysis*

-   *Improve Data Visualization*

-   *Streamline Workflow*

*Here are some of the most common or important packages in R used in the social sciences:*

-   ***`ggplot2`:** Customizable plots*

-   ***`dplyr`:** Data manipulation*

-   ***`tidyr`:** Cleaning data*

-   ***`stringr`:** String manipulation*

-   ***`lubridate`:** Dates and times*

-   ***`psych`:** Psychometrics and psychological research*

-   ***`lme4`:** Linear and generalized linear mixed-effects models*

-   ***`afex`:** Factorial analysis*

-   ***`bayesplot`**or**`brms`:** Bayesian statistics*

*The **`tidyverse`** is a collection of R packages designed for data science. The core packages included in tidyverse are **`ggplot2`, `tidyr`, `readr`, `dplyr`,** and**`stringr`.** You can also download these packages separately.*

### 3. Reading data.

#### 1. Loading a file

You can find your data either using the `file.choose()` function or by clicking on `Files` in the bottom right window. Make sure to save your new data in your local `Environment` in the top right window.

#### 2. CSV Files

The most common format for data files is CSV (Comma-Separated Values). The `readr` package from the `tidyverse` provides functions to read CSV files efficiently.

```{r}
library(tidyverse)
# Read CSV file
data <- read.csv("exercise_data.csv")
```

#### 3. Excel Files

```{r}
library(readxl)

# Read the first sheet
data <- read_excel("/Users/owencallahan/Downloads/Fitness.xlsx")

# Read a specific sheet by name
data_sheet <- read_excel("/Users/owencallahan/Downloads/Fitness.xlsx", sheet = "Sheet1")

# Read a specific sheet by index
data_index <- read_excel("/Users/owencallahan/Downloads/Fitness.xlsx", sheet = 1)
```

#### 4. Writing Data

```{r}
data <- c(1,2,3,4)
write.csv(data, "my_data.csv")
```

### 4. Tidying Data

*Tidying data is an essential part of data analysis in R, making your data easier to work with and analyze. We'll use the tidyverse suite of packages, which includes dplyr, tidyr, and readr among others. Below is a step-by-step tutorial with code examples to demonstrate how to tidy data in R.*

#### 1. Structuring Data formats.

**Pivoting longer:**

```{r}
wide_data <- tibble(
  id = 1:3,
  age = c(25, 30, 35),
  height = c(175, 180, 165),
  weight = c(70, 80, 65)
)

# Convert to long format
long_data <- wide_data %>%
  pivot_longer(cols = c(age, height, weight), names_to = "measure", values_to = "value")

print(long_data)
```

**Pivoting wider:**

```{r}
# Convert back to wide format
wide_again <- long_data %>%
  pivot_wider(names_from = measure, values_from = value)

print(wide_again)

```

**Separate columns:**

```{r}
data <- tibble(
  name = c("John_Doe", "Jane_Smith", "Alice_Johnson")
)

# Separate into first and last names
separated_data <- data %>%
  separate(name, into = c("first_name", "last_name"), sep = "_")

print(separated_data)
```

**Unite columns:**

```{r}
united_data <- separated_data %>%
  unite("full_name", first_name, last_name, sep = " ")
```

#### 2. Select, filter, mutate, and summarize data.

**Selecting Columns**

```{r}
selected_data <- mtcars %>%
  select(cyl, gear)

head(selected_data)
```

**Filtering Rows**

```{r}
filtered_data <- mtcars %>%
  filter(gear < 4)

head(filtered_data)
```

**Mutating Columns**

```{r}
mutated_data <- mtcars %>%
  mutate(speed.scale = qsec/wt)

head(mutated_data %>%
        select(speed.scale))
```

**Summarizing Data**

```{r}
summary_data <- mtcars %>%
  group_by(gear) %>%
  summarize(
    average_wt = mean(wt),
    count = n()
  )

print(summary_data)
```

#### 3. Handle missing values.

```{r}
# Identify missing values
missing_data <- mtcars %>%
  filter(is.na(wt))

# Remove rows with missing values
cleaned_data <- data %>%
  drop_na()

# Replace missing values with a specific value
filled_data <- data %>%
  replace_na(list(height = 170, weight = 70))
```

#### 4. Combine datasets.

```{r}
data1 <- tibble(
  id = 1:3,
  name = c("John", "Jane", "Alice")
)

data2 <- tibble(
  id = 1:3,
  score = c(85, 90, 78)
)

# Inner join
joined_data <- data1 %>%
  inner_join(data2, by = "id")

print(joined_data)
```

### 5. Functions

*When I learned how to create my own functions, I felt like the creative side of R expanded beyond my expectations. I could tailor a command to address exactly what I needed to perform on a given set of data.*

#### 1. Building Functions

*The `function()` command is a fundamental building block in R, enabling users to create their own functions. This is crucial for both simplifying repetitive tasks and organizing code in a clean, efficient manner. Here's what the `function()` command can do for new learners using R:*

-   **Encapsulate Repetitive Tasks**

    -   *Creating functions allows you to encapsulate repetitive code into reusable blocks. This reduces redundancy and makes your scripts more concise and readable. For example, if you frequently perform the same data transformation, you can write a function for it and call it whenever needed.*

-   **Organize Code**

    -   *Functions help in organizing code logically. By breaking down complex procedures into smaller, manageable functions, you make your code more modular and easier to debug and maintain.*

-   **Improve Readability**

    -   *Using functions can significantly enhance the readability of your code. Descriptive function names and clear parameter definitions help others (and your future self) understand the purpose and usage of the code more quickly.*

-   **Parameterization**

    -   *Functions allow you to use parameters to make your code more flexible. Instead of hard-coding values, you can pass different arguments to your functions, making them adaptable to various inputs and scenarios.*

-   **Enhance Reproducibility**

    -   *Functions contribute to reproducibility in your analyses. By encapsulating specific tasks, you ensure that the same operations can be repeated with different data or settings, leading to consistent results.*

-   **Promote Code Reuse**

    -   *Once you write a function, you can reuse it across different projects. This saves time and effort, as you don't need to rewrite the same code for similar tasks.*

***Example of Using `function()` in R***

```{r}
# Define a function to calculate the mean of a numeric vector
calculate_mean <- function(numbers) {
  mean_value <- mean(numbers)
  return(mean_value)
}

# Use the function with a numeric vector
sample_data <- c(4, 8, 15, 16, 23, 42)
average <- calculate_mean(sample_data)
print(average)
```

#### 2. Correlation Analysis

Correlation measures the strength and direction of the relationship between two variables.

```{r}
# Correlation matrix
cor_matrix <- cor(mtcars)
print(cor_matrix)

# Correlation between two variables
cor(mtcars$mpg, mtcars$hp)
```

#### 3. Linear Regression

Linear regression models the relationship between a dependent variable and one or more independent variables.

```{r}
# Simple linear regression
model <- lm(mpg ~ hp, data = mtcars)
summary(model)

# Multiple linear regression
model2 <- lm(mpg ~ hp + wt, data = mtcars)
summary(model2)
```

#### 4. ANOVA (Analysis of Variance)

ANOVA tests the difference in means among groups.

```{r}
# One-way ANOVA
anova_model <- aov(mpg ~ as.factor(cyl), data = mtcars)
summary(anova_model)

# Two-way ANOVA
anova_model2 <- aov(mpg ~ as.factor(cyl) + as.factor(gear), data = mtcars)
summary(anova_model2)
```

#### 5. T-tests

T-tests compare the means of two groups.

```{r}
# One-sample t-test
t.test(mtcars$mpg, mu = 20)
# Two-sample t-test
t.test(mpg ~ as.factor(am), data = mtcars)
```

#### 6. Chi-Square Test

Chi-square tests are used for categorical data to test relationships between variables.

```{r}
# Create a contingency table
table_data <- table(mtcars$cyl, mtcars$gear)

# Chi-square test
chisq.test(table_data)
```

#### 7. Principal Component Analysis (PCA)

PCA reduces the dimensionality of the data while preserving as much variance as possible. An excellent tutorial on PCA can be found by clicking this link: [https://www.youtube.com/watch?](https://www.youtube.com/watch?v=FgakZw6K1QQ)

```{r}
# Perform PCA
pca_result <- prcomp(mtcars, scale. = TRUE)

# Summary of PCA
summary(pca_result)
```

#### 8. K-Means Clustering

K-means clustering groups data into k clusters.

```{r}
# Perform K-means clustering on the mtcars dataset
set.seed(123)
kmeans_result <- kmeans(mtcars[, c("mpg", "hp")], centers = 3)

# Add cluster results to the original mtcars data
mtcars$cluster <- as.factor(kmeans_result$cluster)

# Print the first few rows to check the results
head(mtcars)
```

#### 9. Logistic Regression

Logistic regression models the probability of a binary outcome.

```{r}
# Logistic regression
logit_model <- glm(am ~ hp + wt, data = mtcars, family = binomial)
summary(logit_model)
```

#### 10. Time Series Analysis

```{r}
# Decomposition

# Sample time series data
ts_data <- ts(AirPassengers, frequency = 12)

# Decompose the time series
decomposed <- decompose(ts_data)
plot(decomposed)

# Forecasting

# Install and load the forecast package
library(forecast)

# Fit an ARIMA model
fit <- auto.arima(ts_data)
forecasted <- forecast(fit, h = 12)
plot(forecasted)
```

### 6. Data Visualization

*Let's explore one of my favorite, and also one of the most essential packages in R, `ggplot2`.*

#### 1. Installation and Loading

*First, you need to install and load the `ggplot2` package:*

```{r}
options(repos = c(CRAN = "https://cloud.r-project.org"))
install.packages("ggplot2")
library(ggplot2)
```

#### 2. Basic Components

`ggplot2` *follows the grammar of graphics, which means you build plots layer by layer. The essential components are:*

-   ***Data**: The dataset you're plotting.*

-   ***Aesthetics (aes)**: The mapping of variables to visual properties like x and y coordinates, colors, sizes, etc.*

-   ***Geometries (geom)**: The type of plot you want to create (e.g., points, lines, bars).*

-   ***Facets**: Subplots based on the values of one or more variables.*

-   ***Scales**: Control how data values are mapped to visual properties.*

-   ***Coordinate Systems**: Control the coordinate space.*

-   ***Themes**: Control the appearance of the plot.*

#### 3. Basic Plot Types

**Scatter Plot**

```{r}
# Load example data
data(mtcars)

# Create a scatter plot
ggplot(data = mtcars, aes(x = wt, y = mpg)) +
  geom_point() +
  labs(title = "Scatter Plot of MPG vs Weight",
       x = "Weight (1000 lbs)",
       y = "Miles Per Gallon (MPG)")
```

**Line Plot**

```{r}
# Create a line plot
ggplot(data = mtcars, aes(x = wt, y = mpg)) +
  geom_line() +
  labs(title = "Line Plot of MPG vs Weight",
       x = "Weight (1000 lbs)",
       y = "Miles Per Gallon (MPG)")
```

**Bar Plot**

```{r}
# Create a bar plot
ggplot(data = mtcars, aes(x = factor(cyl))) +
  geom_bar() +
  labs(title = "Bar Plot of Cylinder Counts",
       x = "Number of Cylinders",
       y = "Count")
```

**Histogram**

```{r}
# Create a histogram
ggplot(data = mtcars, aes(x = mpg)) +
  geom_histogram(binwidth = 2) +
  labs(title = "Histogram of MPG",
       x = "Miles Per Gallon (MPG)",
       y = "Frequency")
```

**Box Plot**

```{r}
# Create a box plot
ggplot(data = mtcars, aes(x = factor(cyl), y = mpg)) +
  geom_boxplot() +
  labs(title = "Box Plot of MPG by Cylinder Count",
       x = "Number of Cylinders",
       y = "Miles Per Gallon (MPG)")
```

#### 4. Customizing Plots

**Adding Colors**

```{r}
# Scatter plot with color
ggplot(data = mtcars, aes(x = wt, y = mpg, color = factor(cyl))) +
  geom_point() +
  labs(title = "Scatter Plot of MPG vs Weight by Cylinder Count",
       x = "Weight (1000 lbs)",
       y = "Miles Per Gallon (MPG)",
       color = "Cylinders")
```

**Adding Size**

```{r}
# Scatter plot with color and size
ggplot(data = mtcars, aes(x = wt, y = mpg, color = factor(cyl), size = hp)) +
  geom_point() +
  labs(title = "Scatter Plot of MPG vs Weight by Cylinder Count",
       x = "Weight (1000 lbs)",
       y = "Miles Per Gallon (MPG)",
       color = "Cylinders",
       size = "Horsepower")
```

**Faceting**

```{r}
# Faceted scatter plot
ggplot(data = mtcars, aes(x = wt, y = mpg)) +
  geom_point() +
  facet_wrap(~ cyl) +
  labs(title = "Scatter Plot of MPG vs Weight by Cylinder Count",
       x = "Weight (1000 lbs)",
       y = "Miles Per Gallon (MPG)")
```

**Themes**

```{r}
# Scatter plot with theme
ggplot(data = mtcars, aes(x = wt, y = mpg)) +
  geom_point() +
  labs(title = "Scatter Plot of MPG vs Weight",
       x = "Weight (1000 lbs)",
       y = "Miles Per Gallon (MPG)") +
  theme_minimal()
```
